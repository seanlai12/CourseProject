In this section, we will look into how the function f ( . ) is actually able to distinguish between class labels. We examine three different algorithms, all of which are available in META. We will continue to use the sentiment analysis example, classifying new text into either the positive or negative label. Let's also assume we split our corpus into a training partition and testing partition. The training documents will be used to build f ( . ), and we will be able to evaluate its performance on each testing document. Remember that we additionally have the metadata information Y for all documents, so we know the true labels of all the testing and training data. When used in production, we will not know the true label (unless a human assigns one), but we can have some confidence of the algorithm's prediction based on its performance on the testing data, which mimics the unseen data from the real world. The closer the testing data is to the data you expect to see in the wild, the greater is your belief in the classifier's accuracy. 