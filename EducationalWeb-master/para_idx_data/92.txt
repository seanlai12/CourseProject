the IDF function is an open research question. With the evaluation skills you will learn in Chapter 9, you can test your different instantiations. If we use a linear function like the diagonal line (as shown in the figure), it may not be as reasonable as the IDF function we just defined. In the standard IDF, we have a dropping off point where we say "these terms are essentially not very useful." This makes sense when the term occurs so frequently that it's unlikely to differentiate two documents' relevance (since the term is so common). But, if you look at the linear representation, there is no dropping off point. Intuitively, we want to focus more on the discrimination of low df words rather than these common words. Of course, which one works better still has to be validated by running experiments on a data set. Let's look at the two documents again in Figure 6.11. Without IDF weighting, we just had bit vectors. With IDF weighting, we now can adjust the TF (term frequency) weight by multiplying it with the IDF weight. With this scheme, there is an adjustment by using the IDF value of about which is smaller than the IDF value of presidential. Thus, the IDF will distinguish these two words based on how informative they are. Including the IDF weighting causes d 3 to be ranked above d 2 , since it matched a rare (informative) word, whereas d 2 matched a common (uninformative) word. This shows that the idea of weighting can solve our second problem. How effective is this model in general when we use this TF-IDF weighting? Well, let's take a look at all the documents that we have seen before. In Figure 6.12, we show all the five documents that we have seen before and their new scores using TF-IDF weighting. We see the scores for the first four documents d 3 … news of presidential campaign …  seem to be quite reasonable. But again, we also see a new problem since d 5 did not even have a very high score with our simplest vector space model, but now d 5 has the highest score. This is actually a common phenomenon when designing retrieval functions; when you try to fix one problem, you tend to introduce other problems! That's why it's very tricky to design an effective ranking function, and why finding a "best" ranking function is an open research question. In the next few sections, we'll continue to discuss some additional ideas to further improve this model and try to fix this problem. 