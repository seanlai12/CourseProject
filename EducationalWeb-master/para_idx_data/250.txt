Also recall that we used the maximum likelihood estimate of a unigram language model to find p(w |θ), whereθ in our case is the topic language model associated with documents containing the term computer. That is, After we estimated the topic and background language models, we used the following formula to assign scores to words in our vocabulary: The score indicates how related a word is to our topic language model term computer. Using maximum likelihood estimation, this becomes (14.5) where D is the set of documents containing the term computer and C is the entire collection of documents. We see that words that are more likely to appear in the context of computer will have a greater numerator than denominator, thus increasing the score. Words (such as the) that appear about equally regardless of the context will have a score close to one. Words that usually do not occur in the context of computer will have a denominator less than the numerator, resulting in a score less than one. As mentioned in Section 3.4, there is a slight issue with this normalization formula. For example, assume the word artichoke appears only once in the corpus, and it happens to be in a document where computer is mentioned. Using the above formula will have artichoke and computer very highly related, even though we know this is not true. One way to solve this problem is to smooth a maximum likelihood estimator by pretending that we have observed an extra pseudo count of every word, including unseen words. Thus, the formula for computing a smoothed background language model would be (14.6) where |C| is the total count of all the words in collection C, and |V | is the size of the complete vocabulary set. Note that the variable |V | in the denominator is the total number of pseudo counts we have added to all the words in the vocabulary. 