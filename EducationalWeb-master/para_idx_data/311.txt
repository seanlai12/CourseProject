A natural idea to address the problems of using one single term to denote a topic is to use more words to describe the topic, which would immediately address the first problem of lack of expressive power. When we have more words that we can use to describe the topic, we would be able to describe complicated topics. To address the second problem (of how to involve related words), we need to introduce weights on words. This is what allows us to distinguish subtle differences in topics, and to introduce semantically related words in a quantitative manner. Finally, to solve the problem of word ambiguity, we need to "split" ambiguous words to allow them to be used to (potentially) describe multiple topics. It turns out that all these can be elegantly achieved by using a probability distribution over words (i.e., a unigram language model) to denote a topic, as shown in Figure 17.7. Here, you see that for every topic, we have a word distribution over all the words in the vocabulary. For example, the high probability words for the topic "sports" are sports, game, basketball, football, play, and star. These are all intuitively sports-related terms whose occurrences should contribute to the likelihood of covering the topic "sports" in an article. Note that, in general, the distribution may give all the words a non-zero probability since there is always a very very small chance that even a word not so related to the topic would be mentioned in an article about the topic. Note also that these probabilities for all the words always sum to one for each topic, thus forming a probability distribution over all the words. Such a word distribution represents a topic in that if we sample words from the distribution, we tend to see words that are related to the topic. It is also interesting to note that as a very special case, if the probability of the mass is concentrated entirely on just one word, e.g., sports, then the word distribution representation of a topic would degenerate to the simplest representation of a topic as just one single word discussed before. In this sense, the word distribution representation is a natural generalization and extension of the single-term representation. 