where LS is the linear sum of the n points (i.e., n i=1 x i ), and SS is the square sum of the data points (i.e., n i=1 x i 2 ). A clustering feature is essentially a summary of the statistics for the given cluster. Using a clustering feature, we can easily derive many useful statistics of a cluster. For example, the cluster's centroid, x 0 , radius, R, and diameter, D, are Here, R is the average distance from member objects to the centroid, and D is the average pairwise distance within a cluster. Both R and D reflect the tightness of the cluster around the centroid. Summarizing a cluster using the clustering feature can avoid storing the detailed information about individual objects or points. Instead, we only need a constant size of space to store the clustering feature. This is the key to BIRCH efficiency in space. Moreover, clustering features are additive. That is, for two disjoint clusters, C 1 and C 2 , with the clustering features CF 1 = n 1 , LS 1 , SS 1 and CF 2 = n 2 , LS 2 , SS 2 , respectively, the clustering feature for the cluster that formed by merging C 1 and C 2 is simply (10.11) Example 10.5 Clustering feature. Suppose there are three points, (2, 5), (3, 2), and (4, 3), in a cluster, C 1 . The clustering feature of C 1 is CF 1 = 3, (2 + 3 + 4, 5 + 2 + 3), (2 2 + 3 2 + 4 2 , 5 2 + 2 2 + 3 2 ) = 3, (9, 10), (29, 38) . Suppose that C 1 is disjoint to a second cluster, C 2 , where CF 2 = 3, (35, 36), (417, 440) . The clustering feature of a new cluster, C 3 , that is formed by merging C 1 and C 2 , is derived by adding CF 1 and CF 2 . That is, CF 3 = 3 + 3, (9 + 35, 10 + 36), (29 + 417, 38 + 440) = 6, (44, 46), (446, 478) . A CF-tree is a height-balanced tree that stores the clustering features for a hierarchical clustering. An example is shown in Figure 10.9. By definition, a nonleaf node in a tree has descendants or "children." The nonleaf nodes store sums of the CFs of their children, and thus summarize clustering information about their children. A CF-tree has two parameters: branching factor, B, and threshold, T. The branching factor specifies the maximum number of children per nonleaf node. The threshold parameter specifies the maximum diameter of subclusters stored at the leaf nodes of the tree. These two parameters implicitly control the resulting tree's size. Given a limited amount of main memory, an important consideration in BIRCH is to minimize the time required for input/output (I/O). BIRCH applies a multiphase clustering technique: A single scan of the data set yields a basic, good clustering, and 