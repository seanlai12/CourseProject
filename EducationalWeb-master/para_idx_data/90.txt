In this section, we will improve the representation of this model from the bit vector model. We saw the bit vector representation essentially counts how many unique query terms match the document. From Figure 6.6 we would like d 4 to be ranked above d 3 , and d 2 is really not relevant. The problem here is that this function couldn't capture the following characteristics. . First, we would like to give more credit to d 4 because it matches presidential more times than d 3 . . Second, matching presidential should be more important than matching about, because about is a very common word that occurs everywhere; it doesn't carry that much content. It's worth thinking at this point about why we have these issues. If we look back at the assumptions we made while instantiating the VS model, we will realize that the problem is really coming from some of those assumptions. In particular, it has to do with how we place the vectors in the vector space. Naturally, in order to fix these problems, we have to revisit those assumptions. A natural thought is to consider multiple occurrences of a term in a document as opposed to binary representation; we should consider the TF instead of just the absence or presence. In order to consider the difference between a document where a query term occurred multiple times and one where the query term occurred just once, we have to consider the term frequency-the count of a term in a document. The simplest way to express the TF of a word w in a document d is With the bit vector, we only captured the presence or absence of a term, ignoring the actual number of times that a term occurred. Let's add the count information back: we will represent a document by a vector with as each dimension's weight. That is, the elements of both the query vector and the document vector will not be zeroes and ones, but instead they will be the counts of a word in the query or the document, as illustrated in Figure 6  d 4 … news of presidential campaign … … presidential candidate … The formula looks identical since we are still using the dot product similarity. The difference is inside of the sum since x i and y i are now different-they're now the counts of words in the query and the document. Because of the change in document representation, the new score has a different interpretation. We can see whether this would fix the problems of the bit vector VS model. Look at the three documents again in Figure 6.8. The query vector is the same because all these words occurred exactly once in the query. The same goes for d 2 and d 3 since none of these words has been repeated. As a result, the score is also the same for both these documents. But, d 4 would be different; here, presidential occurred twice. Thus, the corresponding dimension would be weighted as two instead of one, and the score for d 4 is higher. This means, by using TF, we can now rank d 4 above d 2 and d 3 as we had hoped to. 