In real-world big data applications, we would have both structured data and unstructured text data available to help us make predictions and support decision making. It is thus important to analyze both kinds of data jointly, especially when the goal is to predict some latent real-world variable that is not directly observed in the data. To illustrate this problem setup and the big picture of data mining in general, we show the data mining loop in Figure 19.1. In this figure, we see that there are multiple sensors-including human sensors-to report what we have seen in the real world in the form of data. The data include both non-text data and text data. Our goal is to see if we can predict some values of important real world variables that matter to us. For example, we might be interested in predicting the condition of a bridge, the weather, stock prices, or presidential election results. We are interested in predicting such variables because we might want to act on the inferred values or make decisions based on the inferred values. How can we get from the data to these predicted values? We'll first have to do data mining and analysis of the data. In general, we should try to leverage all the data that we can collect, and joint mining of non-text and text data is critical. Through  analysis of all the data, we can generate multiple predictors of the interesting variables to us. We call these predictors features, and they can further be combined and put into a predictive model to actually predict the value of any interesting variable. The prediction results would then allow us to act and change the world. This is the general process for making a prediction based on any data. It's important to emphasize that a human actually plays a very important role in this process, especially because of the involvement of text data. First, a human user would be involved in the mining of the data. The user can control the generation of these features and can even manually create features. Second, humans can help understand the text data, because text data are created to be consumed by humans, and humans can consume and interpret text data much more effectively than a machine. The challenge, of course, is when there is an enormous amount of text data, since it would not be feasible for humans to read and digest all the information. Thus, machines must help and that's why we need to do text data mining. Sometimes machines can even "see" patterns in data that humans may not see even if they have the time to read all the data. Next, humans also must be involved in building, adjusting and testing a predictive model. In particular, we humans will have important domain knowledge about 19.1 Introduction 415 the prediction problem that we can build into the predictive model. Once we have the predicted values for the variables, humans would be involved in taking actions to change the world or make decisions based on these particular values. Finally, it's interesting that a human could be involved in controlling the sensors to collect the most useful data for prediction. Thus, this forms a data mining loop because as we perturb the sensors, they will collect additional new and potentially more useful data, allowing us to improve the prediction. In this loop, humans will recognize what additional data will need to be collected. Machines can help humans identify what data should be collected next. In general, we want to collect data that is most useful for learning. The study of how to identify data points that would be most helpful for machine learning is often referred to as active learning, which is an important subarea in machine learning. There is a loop from data acquisition to data analysis; from data mining to prediction of values; from actions to change the world; and finally, we observe what happens. We can then decide what additional data have to be collected and adjust the sensors accordingly. Analysis of the prediction errors can help reveal what additional data we need to acquire in order to improve the accuracy of prediction. This big picture is actually very general and can serve as a model for many important applications of big data. Since the focus of the book is on text data, it is useful to consider the special case of the loop shown in Figure 19.2 where the goal is to use text data to infer values of some other variables in the real world that may not be directly related to the text. Such an analysis task is different from a task such as topic mining where the goal is to directly characterize the content of text. In text-based prediction, our goal can be to infer any information about the world. This is, of course, only possible if there exist clues in the text data about the target variable; fortunately, this is often the case since people report everything in text data. In many cases (e.g., stock price prediction), the non-text data (historical stock prices) are much more effective for prediction than text data, though text data can generally help provide additional indicators for the prediction task. Sometimes text data contain more useful indicators than non-text data, and text data alone may also be sufficient for making predictions. Typically, in such a case, the prediction is about human behavior or human preferences or opinions. In general though, text data will be put together with non-text data. In all cases of text-based prediction, there are two important questions. First, what features (indicators) are most useful for the prediction task? Second, how can we generate such effective indicators from text? For convenience, we will use the term "feature" and "indicator" interchangeably. The first question has much to do How can we jointly mine text and non-text data? with the specific prediction problem, and is thus inevitably application-specific. However, there are some generic features we can often start with (like n-grams or topics) as discussed in some previous chapters. Supervised learning methods can be used to learn what features are most effective. The second question has been addressed to some extent in the previous chapters of the book since many techniques that we have introduced can be potentially used to obtain features from text data. For example, topic mining can be very useful to generate topicbased indicators or predictors that can be further fed into a predictive model. Such topic-based features can be mixed with word-based features to enrich the feature representation. Sizes of a certain cluster of terms or cluster of documents may also be potential features. A set of terms with paradigmatic relations may be a better indicator than any single term, and sentiment tags that we may be able to generate based on text data are yet another kind of useful feature for some prediction problems. What has not been discussed is how we can jointly mine text and non-text data together to discover interesting knowledge that could not be otherwise discovered by using either one alone. This interaction is the topic of the chapter. The benefit of joint analysis of text and non-text data can be seen from two different perspectives. First, non-text data can enrich text analysis. Specifically, non-text data can often provide a context for mining text data and thus enable us to partition 19. 2 Contextual Text Mining 417 data in different ways based on the companion non-text data (e.g., partitioning text based on time or location). This opens up possibilities of contextual text mining, or mining text data in the context defined by non-text data to discover context-specific knowledge (such as topics associated with a specific non-text variable such as time), or patterns across different contexts like temporal trends. Second, text data can help interpret patterns discovered from non-text data. For example, if a frequent pattern is discovered from non-text data, we can separate the text data associated with the data instances where the pattern occurs from those associated with the instances that do not match the pattern. We can then analyze the difference between these two sets of text data, which may be associated with the meaning of the pattern, and thus can offer insights about how to interpret the pattern which would otherwise be hard to interpret by only looking at the non-text data. This technique is called pattern annotation and discussed in detail in . 