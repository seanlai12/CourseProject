In summary, we have shown several methods to measure term similarity, which can then be used for term clustering. We started with a unigram language modeling approach, followed by pointwise mutual information. We then briefly introduced two model-based approaches, one based on n-gram language models and one based on neural language models for word embedding. These term clustering methods can be leveraged to improve the computation of similarity between documents or other text objects by allowing inexact matching of terms (e.g., allowing words in the same cluster or with high similarity to "match" with each other). 