The R \ S notation may be read as "R set minus S", i.e., all the elements in R that are not in S. The MMR formulation uses λ ∈ [0, 1] to control relevance versus redundancy; the positive relevance score is discounted by the amount of redundancy (similarity) to the already-selected sentences. Again, the two similarity metrics may be any normalized, symmetric measures. The simplest instantiation for the similarity metric would be cosine similarity, and this is in fact the measure used in Carbonell and Goldstein [1998]. The algorithm may be terminated once an appropriate number of words or sentences is in S, or if the score sim 1 (s , p) is below some threshold. Furthermore, the similarity functions may be tweaked as well. Could you think of a way to include sentence position in the similarity function? That is, if a sentence is far away (dissimilar) from the candidate sentence, we could subtract from the similarity score. Even better, we could interpolate the two values into a new similarity score such as where α ∈ [0, 1] controls the weight between the regular cosine similarity and the distance measure, and d( . , . ) is the number of sentences between the two parameters. Note the "one minus" in front of the distance calculation, since a smaller distance implies a greater similarity. Of course, λ in the MMR formula is also able to be set. In fact, for multi-document summarization, Das and Martins [2007] suggests starting out with λ = 0.3 and then slowly increasing to λ = 0.7. The reasoning behind this is to first emphasize novelty and then default to relevance. This should remind you of the explorationexploitation tradeoff discussed in Chapter 11. 