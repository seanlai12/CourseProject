In practice, we score the document for this query by using a logarithm of the query likelihood: (6.5) We do this to avoid having numerous small probabilities multiplied together, which could cause underflow and precision loss. By transforming using a logarithm, we maintain the order of these documents while simultaneously avoiding the underflow problem. Note the last term in the equation above; in this sum, we have a sum over all the possible words in the vocabulary V and iterate through each word in the query. Essentially, we are only considering the words in the query because if a word is not in the query, its contribution to the sum would be zero. The only part we don't know is this document language model, p(w | d). Therefore, we can convert the retrieval problem into the problem of estimating this document language model so that we can compute the probability of a query being generated by each document. Different estimation methods for p(w | d) lead to different ranking functions, and this is just like the different ways to place a document into a vector in the vector space model. Here, there are different ways to estimate parameters in the language model, which lead to different ranking functions for query likelihood. 