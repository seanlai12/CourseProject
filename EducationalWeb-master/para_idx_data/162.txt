There tends to be a tradeoff between precision and recall, so it is natural to combine them. One metric that is often used is called the F β measure, displayed in Figure 9.3. In the case where β = 1, it's a harmonic mean of precision and recall. Considering the parameter β and after some simplification, we can see the F measure may be written in the form on the right-hand side of the figure. Often, β set to one, which indicates an equal preference towards precision and recall. In the case where β = 1, we have a special case of the F measure, often called F 1 . This is a popular measure that is often used as a combined precision and recall score. If β is not equal to one, it controls the emphasis between precision and recall. It's easy 9.2 Evaluation of Set Retrieval 173 to see that if you have a large precision or large recall then the F 1 measure would be high. But what's interesting is how the tradeoff between precision and recall is captured in the F 1 score. In order to understand the formulation, we can first ask the natural question: Why not combine them using a simple arithmetic mean? That would be likely the most natural way of combining them. Why is this not as good as F 1 , i.e., what's the problem with an arithmetic mean? The arithmetic mean tends to be dominated by large values. That means if you have a very high P or a very high R, then you really don't care about whether the other value is low since the whole sum would be high. This is not the desirable effect because one can easily have a perfect recall by returning all the documents! Then we have a perfect recall and a low precision. This will still give a relatively high average. Such search results are clearly not very useful for users even though the average using this formula would be relatively high. In contrast, the F 1 score will reward a case where precision and recall are roughly similar. So, it would penalize a case with an extremely high result for only one of them. This means F 1 encodes a different tradeoff between them than a simple arithmetic mean. This example shows a very important methodology: when we try to solve a problem, you might naturally think of one solution (e.g., the arithmetic mean), but it's important not to settle on this solution; rather, think whether there are other ways to approach it. Once you have multiple ideas, it's important to analyze their differences and then think about which one makes more sense in a real scenario. To summarize, we talked about precision, which addresses the question: are the retrieval results all relevant? We also talked about recall, which addresses the question: have all the relevant documents been retrieved? These two are the two basic measures in information retrieval evaluation. They are used for many other tasks as well. We talked about F measure as a way to combine precision and recall. We also talked about the tradeoff between precision and recall, and it turns out to depend on the users' search tasks and preferences. 174 Chapter 9 Search Engine Evaluation 9.3 