Overview Over many decades, researchers have designed various different kinds of retrieval models which fall into different categories (see Zhai [2008] for a detailed review). First, one family of the models are based on the similarity idea. Basically, we assume that if a document is more similar to the query than another document is, we would say the first document is more relevant than the second one. So in this case, the ranking function is defined as the similarity between the query and the document. One well-known example of this case is the vector space model [Salton et al. 1975], which we will cover more in detail later in this chapter. The second set of models are called probabilistic retrieval models [Lafferty and Zhai 2003]. In this family of models, we follow a very different strategy. We assume that queries and documents are all observations from random variables, and we assume there is a binary random variable called R (with a value of either 1 or 0) to indicate whether a document is relevant to a query. We then define the score of a document with respect to a query as the probability that this random variable R is equal to 1 given a particular document and query. There are different cases of such a general idea. One is the classic probabilistic model, which dates back to work done in the 1960s and 1970s [Maron andKuhns 1960, Robertson andSparck Jones 1976], another is the language modeling approach [Ponte and Croft 1998], and yet another is the divergence-from-randomness model [Amati and Van Rijsbergen 2002]. We will cover a particular language modeling approach called query likelihood retrieval model in detail later in this chapter. One of the most effective retrieval models derived from the classific probabilistic retrieval framework is BM25 [Robertson and Zaragoza 2009], but since the retrieval function of BM25 is so similar to a vector space retrieval model, we have chosen to cover it as a variant of the vector space model. The third kind of model is probabilistic inference [Turtle and Croft 1990]. Here the idea is to associate uncertainty to inference rules. We can then quantify the probability that we can show that the query follows from the document. This family of models is theoretically appealing, but in practice, they are often reduced to models essentially similar to vector-space model or a regular probabilistic retrieval model. Finally, there is also a family of models that use axiomatic thinking [Fang et al. 2011]. The idea is to define a set of constraints that we hope a good retrieval function satisfies. In this case the problem is to find a good ranking function that can satisfy all the desired constraints. Interestingly, although all these models are based on different thinking, in the end the retrieval functions tend to be very similar and involve similar variables. The axiomatic retrieval framework has proven effective for diagnosing deficiencies of a retrieval model and developing improved retrieval models accordingly (e.g., BM25+ [Lv and Zhai 2011]). Although many models have been proposed, very few have survived extensive experimentation to prove effective and robustness. In this book, we have chosen to cover four specific models (i.e., BM25, pivoted length normalization, query likelihood with JM smoothing, and query likelihood with Dirichlet prior smoothing) that are among the very few most effective and robust models. 1 