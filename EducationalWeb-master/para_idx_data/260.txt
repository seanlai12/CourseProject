same or different clusters. Even if your clustering algorithm performs spectacularly in terms of (for example) intra-cluster similarity, the clusters may not be acceptable from a human viewpoint unless an adequate feature representation was used; it's possible that the feature representation is not able to capture a crucial concept and needs to be reexamined. Chapter 4 gives a good overview of many different textual features supported by META. In the next chapter on text categorization (Chapter 15), we also discuss how choosing the right features plays an important role in the overall classification accuracy. As we saw in this chapter, similarity-based algorithms explicitly encode a similarity function in their implementation. Ideally, this similarity between objects is optimized to maximize intra-cluster coherence and minimize intra-cluster separation. In model-based methods (which will be discussed in Chapter 17), similarity functions are not inherently part of the model; instead, the notion of object similarity is most often captured by probabilistically high co-occurring terms within "similar" objects. Measuring coherence and separation automatically can potentially be accomplished by leveraging a categorization data set; such a corpus has predefined clusters where each document belongs to a particular category. For example, a text categorization corpus could be product descriptions from an online retailer, and each product belongs in a product category, such as kitchenware, books, grocery, and so on. A clustering algorithm would be effective if it was able to partition the products based on their text into categories that roughly matched the predefined ones. A simple measure to evaluate this application would be to consider each output cluster and see if one of the predefined categories dominates the cluster population. In other words, take each cluster C i and calculate the percentage of each predefined class in it. The clustering algorithm would be effective if, for each C i , one predefined category dominates and scarcely appears in other clusters. Effectively, the clustering algorithm recreated the class assignments in the original dataset without any supervision. Of course, however, we have to be careful (if this is a parameter), to set the final number of clusters to match the number of classes. In fact, deciding the optimal number of clusters is a hard problem for all methods! For example, in K-means, the final clusters depend on the initial random starting positions. Thus it's quite common to run the algorithm several times and manually inspect the results. The algorithm G-means [Hamerly and Elkan 2003] reruns K-means in a more principled way, splitting clusters if the data assigned to each cluster is not normally-distributed. Model-based methods may have some advantages in terms of deciding the optimal number of clusters, but the model itself 296 Chapter 14 Text Clustering is often inaccurate. In practice, we may empirically set the number of clusters to a fixed number based on application needs or domain knowledge. Which method works the best highly depends on whether the bias (definition of similarity) reflects our perspective for clustering accurately and whether the assumptions made by an approach hold for the problem and applications. In general, model-based approaches have more potential for doing "complex clustering" by encoding more constraints into the probabilistic model. 