This is what we want for indexing! Experiment with a JavaScript crawler using a technology such as PhantomJS. We've provided a simple script to download a 218 Chapter 10 Web Search page, located at: http://sifaka.cs.uiuc.edu/ir/textdatabook/files/text-scraper.js. Try experimenting with the script to make it a true crawler instead of downloading only a single page. 10.5. Crawling a Domain. Now that you know how to download a single HTML file, you can start crawling a domain. This means starting with some base URL and having the crawler follow and download links up to a certain depth. wget has some nice options that make this very easy. wget --recursive --level=3 --wait=2 --accept html [url] This command tells wget to traverse the site recursively by following links up to a depth of 3. It waits 2 between requests (which is considered polite and will help you from getting blocked). Finally, it is told to only download HTML pages since those are the ones with text that we want to index. The output is kept in the same structure as on the web, downloaded into our working directory. If you don't stop it manually (with CTRL-C), it will continue to crawl until all pages at the specified depth have been downloaded. Start off with a conservative depth, since you will not be sure how many pages are under a certain domain. 10.6. Cleaning HTML Files. Before we add a page to the search engine's index, we will probably want to "clean" the HTML page. This means converting the HTML file into a plaintext file so that the keywords given to the search engine more easily match the words in our crawled document. There are many tools available to convert HTML to text, some of which are even online. For our use though, we want to have a command-line based tool so we can automate it. We suggest using Python or Ruby. Below are two simple programs that both do the same thing.  10.13. After reading Chapter 15, you may have some alternative ideas of how to design a learning to rank algorithm. For example, can you outline an idea of how we can optimize (e.g.) MAP for a set of training queries? 10.14. Thinking back to Chapter 9, what is a good objective function to optimize for learning to rank? Is MAP the best choice? Why or why not? 10.15. Outline a method for combining user feedback with a learning to rank approach. In our many discussions of search engine systems, we have addressed the issue of short-term (ad hoc) information need. This is a temporary need from a static information source, where the user pulls relevant information. Examples are library or web search. Conversely, most users also have long-term information needs, such as filtering or recommending documents (or any other item type) from a dynamic information source; here, the user is pushed information by a system. Examples include a news filter, email filter, movie/book recommender, or literature recommender. Although there is some distinction between a recommender system (emphasizing delivery of useful items to users) and a filtering system (emphasizing exclusion of useless items), the techniques used are similar, so we will use "recommender" and "filtering" interchangeably for convenience. Unlike ad hoc search where we may not get much feedback from a user, in filtering, we can expect to collect a lot of feedback information from the user, making it important to learn from the feedback information to improve filtering performance. In filtering, documents are delivered from some dynamic information source. A system must make a binary decision regarding the relevance of a document to a user as soon as it "arrives." This is more difficult than search where we can simply provide a ranked list and rely on a user to flexibly set the cutoff. On the other hand, since we can collect feedback information, we can expect to get more and more information about what the user likes, making it easier to distinguish relevant documents from non-relevant ones. The essential filtering question is: will user u like item x? Our approach to answering this question defines which of the following two strategies we apply. Collaborative filtering: look at who likes x and characterize u Content-based filtering is to learn what kind of content a user likes and then match the content of a current article with a "content prototype" that we believe describes well what the user likes. Collaborative filtering is to look at what other 222 Chapter 11 Recommender Systems similar users like and assume that if those other users who are similar to you like an item, you may also like it. Note that if we can get user ratings of items, collaborative filtering can be applied to recommend any item. Content-based filtering, however, can only be applied to a case where we know how to measure similarity of items. In any specific application, we will want to combine the two approaches to optimize the filtering performance. Content-based filtering can usually be done by extending a retrieval system to add a thresholding component. There are two challenges associated with threshold setting. First, at the beginning, we must set an initial threshold without requiring much information from a user. Second, over time, we need to learn from feedback to optimize the threshold. Many threshold learning methods have been proposed. In practice, a simple thresholding strategy such as the beta-gamma threshold setting method we will discuss is often good enough. The basic idea behind collaborative filtering is to predict the rating of a current active user u for object x based on a weighted average of the ratings of x given by similar users to u. Thus, we can think of this approach involving two steps: In the first step, we simply "retrieve" similar users to the current user u where similarity is often defined as the similarity between the two vectors for two users. Each user can be represented by a rating vector (i.e., all the ratings given by this user). The similarity of two vectors can be measured based on the cosine similarity or Pearson correlation of the two vectors, which tends to perform very well empirically. In the second step, we compute a weighted average of the ratings of x given by all these retrieved similar users where the weight is the correlation between the active user and the corresponding user (to the weight). As we will see in this chapter, many recommender systems are extensions of the information retrieval systems and techniques we have discussed previously. Therefore, it may be beneficial to read Chapter 6 before this one if the reader is unfamiliar with the basic concepts or terminology. We continue this chapter with content-based recommendation, followed by a section on user-based recommendation (collaborative filtering). Figure 11.1 shows a generic information filtering system where a stream of content is absorbed by a filtering system. Based on either the content of the item or the other users that liked the item, the system decides whether or not to pass the item along to the user. In this section, the filtering system will inspect the content of the item and compare it to both the user's preferences and feedback without considering information from other users. 