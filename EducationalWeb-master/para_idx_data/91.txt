Unfortunately, d 2 and d 3 still have identical scores. We would like to give more credit for matching presidential than matching about. How can we solve this problem in a general way? Is there any way to determine which word should be treated more importantly and which word can be essentially ignored? About doesn't carry that much content, so we should be able to ignore it. We call such a word a stop word. They are generally very frequent and they occur everywhere such that matching it doesn't have any significance. Can we come up with any statistical approaches to somehow distinguish a content word like presidential from a stop word like about? One difference is that a word like about occurs everywhere. If you count the occurrence of the word in the whole collection of M documents (where M 5), then we would see that about has a much higher count than presidential. This idea suggests that we could somehow use the global statistics of terms or some other information to try to decrease the weight of the about dimension in the vector representation of d 2 . At the same time, we hope to somehow increase the weight of presidential in the d 3 vector. If we can do that, then we can expect that d 2 will get an overall score of less than three, while d 3 will get a score of about three. That way, we'll be able to rank d 3 on top of d 2 . This particular idea is called the inverse document frequency (IDF). It is a very important signal used in modern retrieval functions. The document frequency is the count of documents that contain a particular term. Here, we say inverse document frequency because we actually want to reward a word that doesn't occur in many documents. The way to incorporate this into our vector is to modify the frequency count by multiplying it by the IDF of the corresponding word, as shown in Figure 6.9. We can now penalize common words which generally have a low IDF and reward informative words that have a higher IDF. IDF can be defined as IDF(w) = M + 1 df(w) , (6.2) where M is the total number of documents in the collection and df( . ) counts the document frequency (the total number of documents containing w). Let's compare the terms campaign and about. Intuitively, about should have a lower IDF score than campaign since about is a less informative word. For clarity, let's assume M = 10, 000, df(about) = 5000, df(campaign) = 1166, and we use a base two logarithm. Then, IDF(about) = log 10, 001 df(about) = log 10, 001 5000 ≈ 1.0 100 Chapter 6 Retrieval Models and IDF(campaign) = log 10, 001 df(campaign) = log 10, 001 1166 ≈ 3.1. Let k represent df(w); if you plot the IDF function by varying k, then you will see a curve like the one illustrated in Figure 6.10. In general, you can see it would give a higher value for a low df , indicating a rare word. You can also see the maximum value of this function is log(M + 1). The specific function is not as important as the heuristic it captures: penalizing popular terms. Whether there is a better form of 