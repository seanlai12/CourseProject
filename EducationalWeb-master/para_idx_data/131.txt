how to separate the large document string into separate tokens (or features). These token streams are then passed on to the indexer. This is perhaps the most vital part of the system as a whole, since a poor tokenization method will affect all other parts of the indexing, and propagate downstream to the end user. Indexer. This is the module that processes documents and indexes them with appropriate data structures. An Indexer can be run offline. The main challenges are to index large amounts of documents quickly with a limited amount of memory. Other challenges include supporting addition and deletion of documents. Scorer/Ranker. This is the module that takes a query and returns a ranked list of documents. Here the challenge is to implement a retrieval model efficiently so that we can score documents efficiently. Feedback/Learner. This is the module that is responsible for relevance feedback or pseudo feedback. When there is a lot of implicit feedback information such as user clickthroughs available (as in a modern web search engine), this learning module can be fairly sophisticated. It was discussed in detail in the previous chapter, so in this chapter we will just outline how it may be added to an existing system. For the first three items, there are fairly standard techniques that are essentially used in all current search engines. The techniques for implementing feedback, however, highly depend on the learning approaches and applications. Despite this, we did discuss some common methods for feedback in the previous chapter. We will additionally investigate two additional optimizations. These are not required to ensure the correctness of an information retrieval system, but they will enable such a system to be much more efficient in both speed and disk usage. Compression. The documents we index could consume hundreds of gigabytes or terabytes. We can simultaneously save disk space and increase disk read efficiency by losslessly compressing the data in our index, which is usually just integers. 1 Caching. Even after designing and compressing an efficient data structure for document retrieval storage, the system will still be at the mercy of the hard disk speed. Thus, it is common practice to add a cache between the frontfacing API and the document index on disk. The cache will be able to save frequently-accessed term information so the number of slow disk seeks during query-time is reduced. The following sections in this chapter discuss each of the above components in turn. 