You may be wondering how we can compute p(w | θ Q ). This is exactly where the KL-divergence retrieval method is better than the simple query likelihood methodwe can have different ways of computing it! The simplest way is to estimate this probability by the maximum likelihood estimator using the query text as evidence, which gives us Using this estimated value, you should see easily that the KL-divergence scoring formula is essentially the same as the query likelihood retrieval formula as presented in Zhai and Lafferty [2004]. A more interesting way of computing p(w | θ Q ) is to exploit feedback documents. Specifically, we can interpolate the simple p ml (w | θ Q ) with a feedback model p(w | θ F ) estimated based on feedback documents. That is, where α is a parameter that needs to be set empirically. Please note that this α is different from α d in the smoothing formula. Of course, the next question is how to estimate p(w | θ F )? One approach is to assume the following two component mixture model for the feedback documents, 