Presence and absence of w1: p(X w1 = 1) + p(X w1 = 0) = 1 Presence and absence of w2: p(X w2 = 1) + p(X w2 = 0) = 1 Co-occurrences of w1 and w2: We only need to know p(X w1 = 1), p(X w2 = 1), and p(X w1 = 1, X w2 = 1). The first new constraint means if we add up the probabilities of two words co-occurring and the probabilities when the first word occurs and the second word does not occur, we get exactly the probability that the first word is observed. The other three new constraints have a similar interpretation. These equations allow us to compute some probabilities based on other probabilities, and this can simplify the computation. More specifically, if we know the probability that a word is present, then we can easily compute the absence probability. It is very easy to use these equations to compute the probabilities of the presence and absence of each word. Now let's look at the joint distribution. Assume that we also have available the probability that they occurred together. It's easy to see that we can actually compute all the rest of these probabilities based on these, as shown in Figure 13.13. Using the first of the four equations, we can compute the probability that the first word occurred and the second word did not because we know the two probabilities in the boxes. Similarly, using the third equation we can compute the probability that we observe only the second word. The figure shows that we only need to know how to compute the three boxed probabilities, namely the presence of each word and the co-occurrence of both words in a segment. All others can be computed based on them. In general, we can use the empirical count of events in the observed data to estimate the probabilities, as shown in Figure 13.14. A commonly used technique is 