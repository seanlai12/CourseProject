These Q i judgements are created by users that interact with each system. Once we have these judgements, we can compare two or more systems. Each query is run on each system, and we investigate the documents that each system returns. Let's say the query is Q 1 . In the figure we have R A as ranked results from system A and R B as the ranked results from system B. Thus, R A is system A's approximation of relevant documents and R B is system B's approximation. Let's take a look at these results-which is better? As a user, which one would you like? There are some differences and there are some documents that are returned by both systems. But if you look at the results you will feel that maybe system A is better in the sense that we don't have that many documents returned, and among the three documents returned two of them are relevant. That's good; system A is precise. On the other hand, we can also say system B is better because it returned more relevant documents; it returned three instead of two. So which one is better and how do we quantify this? This question highly depends on a user's task, and it depends on the individual users as well! For some users, maybe system A is better if the user is not interested in getting all the relevant documents so he or she doesn't have to read too much. On the other hand, imagine a user might need to have as many relevant documents as possible, for example, in writing a literature survey. You might be in the second category, and then you might find that system B is better. In either case, we'll have to also define measures that would quantify the information need of a user. We will need to define multiple measures because users have different perspectives when looking at the results. 