There are two main methods in text summarization. The first is selection-based or extractive summarization. With this method, a summary consists of a sequence of sentences selected from the original documents. No new sentences are written, hence the summary is extracted. The second method is generation-based or abstractive summarization. Here, a summary may contain new sentences not in any of the original documents. One method that we explore here is using a language model. Previously in this book, we've used language models to calculate the likelihood of some text; in this chapter, we will show how to use a language model in reverse to generate sentences. We also briefly touch on the field of natural language generation in our discussion of abstractive techniques. Following the pattern of previous chapters, we then move on to evaluation of text summarization. The two methods each have evaluation metrics that are particularly focused towards their respective implementation, but it is possible to use (e.g.) an abstractive evaluation metric on a summary generated by an extractive algorithm. Finally, we look into some applications of text summarization and see how they are implemented in real-world systems. Text summarization is a broad field and we only touch on the core concepts in this chapter. For further reading, we recommend that the reader start with Das and Martins [2007], which provides a systematic overview of the field and contains much of the content from this chapter in an expanded form. 