Chapter 7 discussed feedback in a standard information retrieval system. We saw two implementations of feedback: the vector space Rocchio feedback and the query likelihood mixture model for feedback. Both can be implemented with the inverted index and document metadata we've described in the previous sections. For Rocchio feedback, we can use the forward index to obtain the vectors of both the query and feedback documents, running the Rocchio algorithm on that set of vectors. The mixture model feedback method requires a language model to be learned over the feedback documents; again, this can be achieved efficiently by using the term counts from the forward index. The only other information needed is the corpus background probabilities for each term, which can be stored in the term lexicon. With this information, it is now possible to create an online (or "in-memory") pseudo-feedback method. Recall that pseudo-feedback looks at the top k returned documents from search and assumes they are relevant. The following process could be used to enable online feedback. . Run the user's original query. . Use the top k documents and the forward index to either modify the query vector (Rocchio) or estimate a language model and interpolate with the feedback model (query likelihood). . Rerun the search with the modified query and return the new results to the user. There are both advantages and disadvantages to this simple feedback model. For one, it requires very little memory and disk storage to implement since each modified query is "forgotten" as soon as the new results are returned. Thus, we don't need to create any additional storage structures for the index. The downside is that all the processing is done at query time, which could be quite computationally expensive, especially when using a search engine with many users. The completely opposite tradeoff is to store every modified query in a database, and look up its expanded form, running the search function only once. Of course, this is infeasible as the number of queries would quickly make the database explode in size, not to mention that adding more documents to the index would invalidate the stored query vectors (since the new documents might also match the original query). In practice, we can have some compromise between these two extremes, e.g., only storing the very frequently expanded queries, or using query similarity to search for a similar query that has been saved. The caching techniques discussed in a later section are also applicable to feedback methods, so consider how to adopt them from caching terms to caching expanded queries. Of course, this only touches on the pseudo-feedback method. There is also clickthrough data, which can be stored in a database, and relevance judgements, which can be stored the same way. Once we know which documents we'd like to include in the chosen feedback method, all implementations are the same since they deal with a list of feedback documents. 