Re-estimated probability of doc d covering topic θ j Re-estimated probability of word w for topic θ j ML estimate based on "allocated" word counts to topic θ j  we would simply collect all the split counts of words in document d that belong to each θ j , and then normalize these counts among all the k topics. Similarly, to re-estimate p(w | θ j ), we would collect the split counts of a word toward θ j from all the documents in the collection, and then normalize these counts among all the words. Note that the normalizers are very different in these two cases, which are directly related to the constraints we have on these parameters. In the case of re-estimation of π , the constraint is that the π values must sum to one for each document, thus our normalizer has been chosen to ensure that the re-estimated values of π indeed sum to one for each document. The same is true for the reestimation of p(w | θ), where our normalizer allows us to obtain a word distribution for each topic. What we observed here is actually generally true when using the EM algorithm. That is, the distribution of the hidden variables computed in the E-step can be used to compute the expected counts of an event, which can then be aggregated and normalized appropriately to obtain a re-estimate of the parameters. In the implementation of the EM algorithm, we can thus just keep the counts of various events and then normalize them appropriately to obtain re-estimates for various parameters. In Figure 17.34, we show the computation of the EM algorithm for PLSA in more detail. We first initialize all the unknown parameters randomly, including the coverage distribution π d , j for each document d, and the word distribution for each topic p(w | θ j ). After the initialization step, the EM algorithm would go through • Initialize all unknown parameters randomly • Repeat until likelihood converges What's the normalizer for this one? a loop until the likelihood converges. How do we know when the likelihood converges? We can keep track of the likelihood values in each iteration and compare the current likelihood with the likelihood from the previous iteration or the average of the likelihood from a few previous iterations. If the current likelihood is very similar to the previous one (judged by a threshold), we can assume that the likelihood has converged and can stop the algorithm. In each iteration, the EM algorithm would first invoke the E-step followed by the M-step. In the E-step, it would augment the data by predicting the hidden variables. In this case, the hidden variable, z d , w indicates whether word w in d is from a "real" topic or the background. If it's from a real topic, it determines which of the k topics it is from. From Figure 17.34, we see that in the E-step we need to compute the probability of z values for every unique word in each document. Thus, we can iterate over all the documents, and for each document, iterate over all the unique words in the document to compute the corresponding p(z d , w ). This computation involves computing the product of the probability of selecting a topic and the probability of word w given by the selected distribution. We can then normalize these products based on the constraints we have, to ensure k j =1 p(z d , w = j) = 1. In this case, the normalization is among all the topics. In the M-step, we will also collect the relevant counts and then normalize appropriately to obtain re-estimates of various parameters. We would use the estimated probability distribution p(z d , w ) to split the count of word w in document d among all the topics. Note that the same word would generally be split in different ways in different documents. Once we split the counts for all the words in this way, we can aggregate the split counts and normalize them. For example, to re-estimate π d , j 17.5 Extension of PLSA and Latent Dirichlet Allocation 377 (coverage of topic θ j in document d), the relevant counts would be the counts of words in d that have been allocated to topic θ j , and the normalizer would be the sum of all such counts over all the topics so that after normalization, we would obtain a probability distribution over all the topics. Similarly, to re-estimate p(w | θ j ), the relevant counts are the sum of all the split counts of word w in all the documents. These aggregated counts would then be normalized by the sum of such aggregated counts over all the words in the vocabulary so that after normalization, we again would obtain a distribution, this time over all the words rather than all the topics. If we complete all the computation of the E-step before starting the M-step, we would have to allocate a lot of memory to keep track of all the results from the E-step. However, it is possible to interleave the E-step and M-step so that we can collect and aggregate relevant counts needed for the M-step while we compute the E-step. This would eliminate the need for storing many intermediate values unnecessarily. 