The main goal of topic analysis is to try to decode these topics behind the text (by segmenting them), and figure out which words are from which distribution so that we can obtain both characterizations of all the topics in the text data and the coverage of topics in each document. Once we can do these, they can be directly used in many applications such as summarization, segmentation, and clustering. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Lorem ipsum, dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderi t in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Lorem ipsum, dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. i d m i n i m v e niam, quis nostrud exercitation ullamco laboris i t e irure dolor in , quis nostrud exercitation ullamco laboris si ut aliquip ex ea commodo consequat. Duis aute irure dolor. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderi t in voluptate velit esse cillum dolore eu fugiat nulla pariatur. The formal definition of mining multiple topics from text is illustrated in Figure 17.28. The input is a collection of text data, the number of topics, and a vocabulary set. The output is of two types. One is topic characterization where each topic is represented by θ i , which is a word distribution. The other is the topic coverage for each document π ij which refers to the probability that document d i covers topic θ j . Such a problem can be solved by using PLSA, a generalization of the simple twocomponent mixture model to more than two components. Such a more generative model is illustrated in Figure 17.29, where we also retain the background model used in the two-component mixture model (which, if you recall, was designed to discover just one topic). Different from the simple mixture model discussed earlier, the model here includes k component models, each of which represents a distinct topic and can be used to generate a word in the observed text data. Adding the background model θ B , we thus have a total of k + 1 component unigram language models in PLSA. 2 2. The original PLSA [Hofmann 1999] did not include a background language model, thus it gives common words high probabilities in the learned topics if such common words are not removed in the preprocessing stage.  Figure 17.29 Generating words from a mixture of multiple topics. 