Query LM KL-divergence (cross entropy)  So, the two formulas look almost identical except that in the generalized formula we have a probability of a word given by a query language model. Still, we add all the words that are in the document and have non-zero probability for the query language model. Again, this becomes a generalization of summing over all the matching query words. We can recover the original query likelihood formula by simply setting the query language model to be the relative frequency of a word in the query, which eliminates the query length term n = |q| which is a constant. Figure 7.4 shows that we first estimate a document language model, then we estimate a query language model and we compute the KL-divergence, often denoted by D( . || . ). We compute a language model from the documents containing the query terms called the feedback language model θ F . This feedback language model is similar to the positive centroid C r in Rocchio feedback. This model can be combined with the original query language model using a linear interpolation, which produces an updated model, again just like Rocchio. We have a parameter α ∈ [0, 1] that controls the strength of the feedback documents. If α = 0, there is no feedback; if α = 1, we receive full feedback and ignore the original query. Of course, these extremes are generally not desirable. The main question is how to compute this θ F . Now, we'll discuss one of the approaches to estimate θ F . This approach is based on a generative model shown in Figure 7.5. Let's say we are observing the positive documents, which are collected by users' judgements, the top k documents from a search, clickthrough logs, or some other means. One approach to estimate a language model over these documents is to assume these documents are gen- erated from some ideal feedback language model as we did before; this entails normalizing all the frequency counts from all the feedback documents. But is this distribution good for feedback? What would the top-ranked words in θ F be? 