f (q = "presidential campaign news", d ) g ("campaign", d ) g ("news", d ) g ("presidential", d ) "Bag of Words" How many times does "presidential" occur in d? Term frequency (TF): c ("presidential", d) How long is d? Document length: |d| How often do we see "presidential" in the entire collection? Document frequency: DF("presidential") P("presidential"|collection) We can see there are three different components, each corresponding to how well the document matches each of the query words. Inside of these functions, we see a number of heuristics. For example, one factor that affects the function g is how many times the word presidential occurs in each document. This is called a term frequency (TF). We might also denote this as c (presidential, d). In general, if the word occurs more frequently in the document, the value of this function would be larger. Another factor is the document length. In general, if a term occurs in a long document many times, it is not as significant as if it occurred the same number of times in a short document (since any term is expected to occur more frequently in a long document). Finally, there is a factor called document frequency. This looks at how often presidential occurs at least once in any document in the entire collection. We call this the document frequency, or DF, of presidential. DF attempts to characterize the popularity of the term in the collection. In general, matching a rare term in the collection is contributing more to the overall score than matching a common term. TF, DF, and document length capture some of the main ideas used in pretty much all state-of-the-art retrieval models. In some other models we might also use a probability to characterize this information. A natural question is: Which model works the best? It turns out that many models work equally well, so here we list the four major models that are generally regarded as state-of-the-art: . pivoted length normalization [Singhal et al. 1996]; . Okapi BM25 [Robertson and Zaragoza 2009 PL2 [Amati and Van Rijsbergen 2002]. When optimized, these models tend to perform similarly as discussed in detail in Fang et al. [2011]. Among all these, BM25 is probably the most popular. It's most likely that this has been used in virtually all search engine implementations, and it is quite common to see this method discussed in research papers. We'll talk more about this method in a later section. In summary, the main points are as follows. First, the design of a good ranking function requires a computational definition of relevance, and we achieve this goal by designing a proper retrieval model. Second, many models are equally effective but we don't have a single winner. Researchers are still actively working on this problem, trying to find a truly optimal retrieval model. Finally, the state-of-the-art ranking functions tend to rely on the following ideas: (1) bag of words representation; and (2) TF and the document frequency of words. Such information is used by a ranking function to determine the overall contribution of matching a word, with an adjustment for document length. These are often combined in interesting ways. We'll discuss how exactly they are combined to rank documents later in this book. 