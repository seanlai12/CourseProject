In this section, we describe distance measures that are commonly used for computing the dissimilarity of objects described by numeric attributes. These measures include the Euclidean, Manhattan, and Minkowski distances. In some cases, the data are normalized before applying distance calculations. This involves transforming the data to fall within a smaller or common range, such as [−1, 1] or [0.0, 1.0]. Consider a height attribute, for example, which could be measured in either meters or inches. In general, expressing an attribute in smaller units will lead to a larger range for that attribute, and thus tend to give such attributes greater effect or "weight." Normalizing the data attempts to give all attributes an equal weight. It may or may not be useful in a particular application. Methods for normalizing data are discussed in detail in Chapter 3 on data preprocessing. The most popular distance measure is Euclidean distance (i.e., straight line or "as the crow flies"). Let i = (x i1 , x i2 , . . . , x ip ) and j = (x j1 , x j2 , . . . , x jp ) be two objects described by p numeric attributes. The Euclidean distance between objects i and j is defined as (2.16) Another well-known measure is the Manhattan (or city block) distance, named so because it is the distance in blocks between any two points in a city (such as 2 blocks down and 3 blocks over for a total of 5 blocks). It is defined as Both the Euclidean and the Manhattan distance satisfy the following mathematical properties: Non-negativity: d(i, j) ≥ 0: Distance is a non-negative number. Identity of indiscernibles: d(i, i) = 0: The distance of an object to itself is 0. Distance is a symmetric function. Going directly from object i to object j in space is no more than making a detour over any other object k. A measure that satisfies these conditions is known as metric. Please note that the non-negativity property is implied by the other three properties. Example 2.19 Euclidean distance and Manhattan distance. Let x 1 = (1, 2) and x 2 = (3, 5) represent two objects as shown in Figure 2.23. The Euclidean distance between the two is √ 2 2 + 3 2 = 3.61. The Manhattan distance between the two is 2 + 3 = 5. Minkowski distance is a generalization of the Euclidean and Manhattan distances. It is defined as where h is a real number such that h ≥ 1. (Such a distance is also called L p norm in some literature, where the symbol p refers to our notation of h. We have kept p as the number of attributes to be consistent with the rest of this chapter.) It represents the Manhattan distance when h = 1 (i.e., L 1 norm) and Euclidean distance when h = 2 (i.e., L 2 norm). The supremum distance (also referred to as L max , L ∞ norm and as the Chebyshev distance) is a generalization of the Minkowski distance for h → ∞. To compute it, we find the attribute f that gives the maximum difference in values between the two objects. This difference is the supremum distance, defined more formally as: (2.19) The L ∞ norm is also known as the uniform norm. x 2 = (3, 5) x 1 = (1, 2) Euclidean distance = (2 2 + 3 2 ) 1/2 = 3.61 Manhattan distance = 2 + 3 = 5 Supremum distance = 5 -2 = 3 Example 2.20 Supremum distance. Let's use the same two objects, x 1 = (1, 2) and x 2 = (3, 5), as in Figure 2.23. The second attribute gives the greatest difference between values for the objects, which is 5 − 2 = 3. This is the supremum distance between both objects. If each attribute is assigned a weight according to its perceived importance, the weighted Euclidean distance can be computed as (2.20) Weighting can also be applied to other distance measures as well. 