2. Query words are generated independently, allowing us to decompose the probability of the whole query into a product of probabilities of observed words in the query. 3. If a word is not seen in the document, its probability is proportional to its probability in the collection (smoothing with the background collection). 4. Finally, we made one of two assumptions about the smoothing, using either Jelinek-Mercer smoothing or Dirichlet prior smoothing. If we make these four assumptions, then we have no choice but to take the form of the retrieval function that we have seen earlier. Fortunately, the function has a nice property in that it implements TF-IDF weighting and document length normalization. In practice, these functions also work very well. In that sense, these functions are less heuristic compared with the vector space model. 