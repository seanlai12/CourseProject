square loss defined on the difference of the topic selection probabilities of the two neighboring nodes u and v: k j =1 (p(θ j | u) − p(θ j | v)) 2 , which strongly prefers to give p(θ j | u) and p(θ j | v) similar values. In front of this regularization term, we see a weight w (u, v), which is based on our network context where the edges may be weighted. This weight states that the more connected the two nodes are, the more important it is to ensure the two nodes have similar topics. In the case when the edges are not weighted, we may set w(u, v) = 1 if there exists an edge between u and v, and w(u, v) = 0 otherwise, essentially to keep only the regularizer for edges that exist on the graph. Note that there's a negative sign in front of the regularizer because while we want to maximize the likelihood part, we want to minimize the loss defined by the regularizer. Such a modified optimization problem can still be solved using a variant of the EM algorithm, called General EM, where in the M-step, the algorithm does not attempt to find a maximum of the auxiliary function, but instead, just finds a new parameter value that would increase the value of the auxiliary function, thus also ensuring an increase of the likelihood function due to the fact that the auxiliary function is a lower bound of the original function (see Section 17.3.5 on the EM algorithm for more explanation about this). The whole algorithm is still a hillclimbing algorithm with guarantee of convergence to a local maximum. In Figure 19.12, we show the four major topics discovered using the standard PLSA from a bibliographic database data set DBLP which consists of titles of papers from four research communities, including information retrieval (IR), data mining  (DM), machine learning (ML), and World Wide Web (Web). The data set has been constructed by pooling together papers from these research communities, and our goal is to see if NetPLSA can more successfully learn topics well aligned to the communities than the standard PLSA. The results in Figure 19.12 show that PLSA is unable to generate the four communities that correspond to our intuition. The reason was because they are all mixed together and there are many words that are shared by these communities, and the co-occurrence statistics in the data are insufficient for separating them. In contrast, the results of NetPLSA, shown in Figure 19.13, are much more meaningful, and the four topics correspond well to the four communities that we intend to discover from the data set. Indeed, it is very easy to label them with the four communities as shown in the table. The reason why NetPLSA can separate these communities well and discover more meaningful topics is because of the influence of the network context. Since our network is the collaboration network of authors, when we impose the preference for two nodes connected in the network to have similar topics, the model would further tune the discovered topics to better reflect the topics worked on by authors involved in the same collaboration network. As a result, the topics would be more coherent and also better correspond to the communities (represented by subnetworks of collaboration). These results are also useful for characterizing the content associated with each subnetwork of collaboration. Taking a more general view of text mining in the context of networks, we can treat text data as living in a rich information network environment. That is, we can 