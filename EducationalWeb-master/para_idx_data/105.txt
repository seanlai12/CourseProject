When calculating the query likelihood retrieval score, recall that we take a sum of log probabilities over all of the query words, using the probability of a word in the query given the document (i.e., the document language model). The main task now is to estimate this document language model. In this section we look into this task in more detail. First of all, how do we estimate this language model? The obvious choice would be the maximum likelihood estimation (MLE) that we have seen before in Chapter 2. In MLE, we normalize the word frequencies in the document by the document length. Thus, all the words that have the same frequency count will have an equal probability under this estimation method. Note that words that have not occurred in the document will have zero probability. In other words, we assume the user will sample a word from the document to formulate the query, and there is no chance of sampling any word that is not in the document. But we know that's not good, so how would we improve this? In order to assign a non-zero probability to words that have not been observed in the document, we would have to take away some 6.4 Probabilistic Retrieval Models 119 probability mass from seen words because we need some extra probability mass for the unseen words-otherwise, they won't sum to one. To make this transformation and to improve the MLE, we will assign nonzero probabilities to words that are not observed in the data. This is called smoothing, and smoothing has to do with improving the estimate by including the probabilities of unseen words. Considering this factor, a smoothed language model would be a more accurate representation of the actual document. Imagine you have seen the abstract of a research paper; or, imagine a document is just an abstract. If we assume words that don't appear in the abstract have a probability of zero, that means sampling a word outside the abstract is impossible. Imagine the user who is interested in the topic of this abstract; the user might actually choose a word that is not in the abstract to use as query. In other words, if we had asked this author to write more, the author would have written the full text of the article, which contains words that don't appear in the abstract. So, smoothing the language model is attempting to try to recover the model for the whole article. Of course, we don't usually have knowledge about the words not observed in the abstract, so that's why smoothing is actually a tricky problem. The key question here is what probability should be assigned to those unseen words. As one would imagine, there are many different approaches to solve this issue. One idea that's very useful for retrieval is to let the probability of an unseen word be proportional to its probability as given by a reference language model. That means if you don't observe the word in the corpus, we're going to assume that its probability is governed by another reference language model that we construct. It will tell us which unseen words have a higher probability than other unseen words. In the case of retrieval, a natural choice would be to take the collection LM as the reference LM. That is to say if you don't observe a word in the document, we're going to assume that the probability of this word would be proportional to the probability of the word in the whole collection. More formally, we'll be estimating the probability of a word given a document as follows: If the word is seen in the document, then the probability would be a discounted MLE estimate p seen . Otherwise, if the word is not seen in the document, we'll let the probability be proportional to the probability of the word in the collection p(w | C), with the coefficient α d controlling the amount of probability mass that we assign 120 Chapter 6 Retrieval Models  to unseen words. Regardless of whether the word w is seen in the document or not, all these probabilities must sum to one, so α d is constrained. Now that we have this smoothing formula, we can plug it into our query likelihood ranking function, illustrated in Figure 6.24. In this formula, we have a sum over all the query words, written in the form of a sum over the corpus vocabulary. Although we sum over words in the vocabulary, in effect we are just taking a sum of query words since each word is weighted by its frequency in the query. Such a way to write this sum is convenient in some transformations. In our smoothing method, we're assuming the words that are not observed in the document have a somewhat different form of probability. Using this form we can decompose this sum into two parts: one over all the query words that are matched in the document and the other over all the words that are not matched. These unmatched words have a different form of probability because of our assumption about smoothing. We can then rewrite the second sum (of query words not matched in d) as a difference between the scores of all words in the vocabulary minus all the query words matched in d. This is actually quite useful, since part of the sum over all w ∈ V can now be written as |q| log α d . Additionally, the sum of query words matched in d 6.4 Probabilistic Retrieval Models 121 Ignore for ranking 